{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UkDauX8Byb3"
      },
      "outputs": [],
      "source": [
        "from submit import my_fit, my_predict\n",
        "import time as tm\n",
        "import pickle\n",
        "import warnings\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdq2X6uVB8rh"
      },
      "outputs": [],
      "source": [
        "with open( \"dict_secret\", 'r' ) as f:\n",
        "\twords = f.read().split( '\\n' )[:-1]\t\t# Omit the last line since it is empty\n",
        "\tnum_words = len( words )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQrLNsaGB-f_"
      },
      "outputs": [],
      "source": [
        "n_trials = 5\n",
        "\n",
        "t_train = 0\n",
        "m_size = 0\n",
        "t_test = 0\n",
        "prec = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAsWDD5iChyt"
      },
      "outputs": [],
      "source": [
        "def get_bigrams( word, lim = None ):\n",
        "  # Get all bigrams\n",
        "  bg = map( ''.join, list( zip( word, word[1:] ) ) )\n",
        "  # Remove duplicates and sort them\n",
        "  bg = sorted( set( bg ) )\n",
        "  # Make them into an immutable tuple and retain only the first few\n",
        "  return tuple( bg )[:lim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC5OSDt9CF1p"
      },
      "outputs": [],
      "source": [
        "lim_bg = 5\n",
        "lim_out = 5\n",
        "\n",
        "for t in range( n_trials ):\n",
        "  tic = tm.perf_counter()\n",
        "  model = my_fit( words )\n",
        "  toc = tm.perf_counter()\n",
        "  t_train += toc - tic\n",
        "\n",
        "  with open( f\"model_dump_{t}.pkl\", \"wb\" ) as outfile:\n",
        "    pickle.dump( model, outfile, protocol = pickle.HIGHEST_PROTOCOL )\n",
        "\n",
        "  m_size += os.path.getsize( f\"model_dump_{t}.pkl\" )\n",
        "\n",
        "  tic = tm.perf_counter()\n",
        "\n",
        "  for ( i, word ) in enumerate( words ):\n",
        "    bg = get_bigrams( word, lim = lim_bg )\n",
        "    guess_list = my_predict( model, bg )\n",
        "\n",
        "    # Do not send long guess lists -- they will result in lower marks\n",
        "    guess_len = len( guess_list )\n",
        "    # Ignore all but the first 5 guesses\n",
        "    guess_list = guess_list[ :lim_out ]\n",
        "\n",
        "    # Notice that if 10 guesses are made, one of which is correct,\n",
        "    # score goes up by 1/10 even though only first 5 guesses are considered\n",
        "    # Thus, it is never beneficial to send more than 5 guesses\n",
        "    if word in guess_list:\n",
        "      prec += 1 / guess_len\n",
        "\n",
        "  toc = tm.perf_counter()\n",
        "\n",
        "  t_test += toc - tic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmub4R58CJ1E"
      },
      "outputs": [],
      "source": [
        "t_train /= n_trials\n",
        "m_size /= n_trials\n",
        "t_test /= n_trials\n",
        "prec /= ( n_trials * num_words )\n",
        "\n",
        "print( t_train, m_size, prec, t_test )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
